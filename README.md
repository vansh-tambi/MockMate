# ğŸ¯ MockMate

> **Interview evaluation grounded in real standards, not hallucinations**

Traditional AI interview tools give you arbitrary scores and generic feedback. MockMate evaluates your answers against a curated question bank using RAG (Retrieval-Augmented Generation), providing explainable scores and specific, actionable feedback.

![Local AI](https://img.shields.io/badge/Local_AI-Phi--3-blue?style=flat)
![RAG](https://img.shields.io/badge/RAG-FAISS-green?style=flat)
![Built with React](https://img.shields.io/badge/React-19.2-61DAFB?style=flat&logo=react)
![FastAPI](https://img.shields.io/badge/FastAPI-Python-009688?style=flat&logo=fastapi)
![TailwindCSS](https://img.shields.io/badge/TailwindCSS-4.1-38B2AC?style=flat&logo=tailwind-css)
![Portfolio](https://img.shields.io/badge/Portfolio-v1.0-gold?style=flat)

ğŸ“º **[Demo Video Coming Soon]** | ğŸ“– **[Read Case Study](CASE_STUDY.md)** | ğŸ“ **[View Portfolio Descriptions](PORTFOLIO_DESCRIPTIONS.md)**

---

## ğŸ¯ The Problem We Solve

**Most AI interview prep tools:**
- Give you a 67/100 with no context (is that good? bad? what does it mean?)
- Provide generic feedback ("be clearer", "add more detail")
- Inconsistent scoring (same answer, different scores each time)
- Hallucinate strengths that don't exist in your answer

**You never know if you're actually improving or if the AI is just being nice.**

---

## âœ¨ The MockMate Difference

### Grounded Evaluation Using RAG

When you answer a question, MockMate:
1. **Retrieves 3 similar questions** from a curated bank of 52 questions
2. **Extracts their ideal talking points** as reference standards
3. **Judges your answer** against these known good answers
4. **Assigns you to a locked score band** with clear meaning

**Result**: Scores are explainable. Feedback is specific. Progress is measurable.

### Locked Score Bands (Not Arbitrary Numbers)

```
0â€“30    = âŒ INCORRECT      (fundamentally wrong)
31â€“50   = âš ï¸ SURFACE LEVEL  (vague, major gaps)
51â€“70   = âœ“ ACCEPTABLE      (meets interview bar)
71â€“85   = âœ“âœ“ STRONG         (better than most)
86â€“100  = âœ“âœ“âœ“ EXCEPTIONAL   (rare mastery)
```

You know exactly what your score means and how to improve.

### Local-First Architecture

- **Runs on your machine** with Phi-3 via Ollama (fast, free, no API limits)
- **No vendor lock-in** - not dependent on GPT/Claude/Gemini pricing
- **Consistent evaluation** - RAG grounds the AI in reference standards

---

## ğŸ—ï¸ Architecture

```
User Answer â†’ Server â†’ Local AI (Phi-3) â†’ RAG Retrieval â†’ Evaluation
                                              â†“
                                     3 similar questions
                                     with ideal_points
                                              â†“
                                     Grounded score + feedback
```

**Key decisions**:
- **Local AI first** (Phi-3 via Ollama) - Cloud fallback to Gemini only if needed
- **RAG-grounded** - Judge against curated standards, not vibes
- **52 curated questions** - Quality over quantity (Frontend, Backend, DSA, System Design, Behavioral, Product, Marketing, Data)
- **Locked semantics** - Score bands have documented, consistent meanings

---

## âœ¨ Features

### ğŸ¯ **RAG-Grounded Evaluation**
- Answer evaluation against real question bank standards
- Specific, actionable feedback (not "add more detail")
- Explainable scores with clear band meanings
- Consistent scoring across sessions

### ğŸ“ **Guided Study Mode**
- AI-generated interview questions tailored to your resume
- Expandable Q&A cards with ideal talking points
- Regenerate questions for varied practice
- Cross-role support (Frontend, Backend, DSA, Behavioral, Product, etc.)

### ğŸ™ï¸ **Mock Interview Mode**
- Real-time speech-to-text simulation
- Live video feed for presentation practice
- Detailed strength & improvement analysis
- Question navigation and randomization

### ğŸ“„ **Smart Resume Integration**
- PDF upload and text extraction
- Manual resume input option
- Context-aware question generation
- Job description integration

---

## ğŸš€ Quick Start

### Prerequisites

- **Ollama** with `phi3` model ([Install Ollama](https://ollama.ai))
- **Node.js** (v16+)
- **Python 3.8+**
- **Optional**: Google Gemini API Key for cloud fallback ([Get one](https://makersuite.google.com/app/apikey))

### Installation

1. **Clone and install dependencies**
   ```bash
   git clone https://github.com/vansh-tambi/MockMate.git
   cd MockMate
   
   # Server
   cd server && npm install && cd ..
   
   # Client  
   cd client && npm install && cd ..
   
   # AI Service
   cd ai_service
   python -m venv venv
   venv\Scripts\activate  # Windows
   # source venv/bin/activate  # Mac/Linux
   pip install -r requirements.txt
   ```

2. **Set up Ollama**
   ```bash
   # Install Ollama: https://ollama.ai
   ollama pull phi3
   ollama serve
   ```

3. **Configure environment** (Create `.env` files)
   
   `server/.env`:
   ```env
   GEMINI_API_KEY=your_key_here  # Fallback only
   USE_LOCAL_AI=true
   AI_SERVICE_URL=http://localhost:8000
   PORT=5000
   ```
   
   `ai_service/.env`:
   ```env
   OLLAMA_BASE_URL=http://localhost:11434
   MODEL_NAME=phi3
   ```

### Running MockMate

Open 3 terminals:

```bash
# Terminal 1: AI Service
cd ai_service
venv\Scripts\activate
python app.py
# â†’ http://localhost:8000

# Terminal 2: Server
cd server
npm run dev
# â†’ http://localhost:5000

# Terminal 3: Client
cd client
npm run dev
# â†’ http://localhost:5173
```

Then open `http://localhost:5173` in your browser.

---

## ğŸ“Š What Makes This Different

### Before MockMate
```
Q: "Explain React hooks"
A: "Hooks are functions for state"
Score: 67/100
Feedback: "Good job! Try to add more detail."
```
â†’ What does 67 mean? What detail? How do I improve?

### With MockMate
```
Q: "Explain React hooks"
A: "Hooks are functions for state"
Score: 42/100 | âš ï¸ SURFACE LEVEL
Feedback: "Mentioned useState but missed: useEffect for side effects, 
custom hooks for reusability, composition pattern. Add concrete examples 
like custom useLocalStorage hook."
```
â†’ Clear band. Specific gaps. Actionable next steps.

**Why?** RAG retrieved similar React hooks questions and compared your answer to known ideal points.

---

## ğŸ› ï¸ Tech Stack

### AI & RAG
- **Ollama + Phi-3** - Local LLM for evaluation
- **FAISS** - Vector similarity search
- **Sentence Transformers** - Semantic embeddings
- **FastAPI** - AI service backend

### Frontend
- **React 19** - UI framework
- **Vite** - Build tool
- **TailwindCSS** - Styling
- **Framer Motion** - Animations
- **Web Speech API** - Voice recognition

### Backend
- **Node.js + Express** - API server
- **Google Gemini** - Cloud fallback (optional)
- **Multer** - File uploads
- **pdf-parse** - Resume parsing

---

## ğŸ“‚ Project Structure

```
MockMate/
â”œâ”€â”€ ai_service/          # FastAPI + RAG + Local LLM
â”‚   â”œâ”€â”€ app.py           # Main evaluation endpoint
â”‚   â”œâ”€â”€ rag/             # Retrieval-Augmented Generation
â”‚   â”‚   â”œâ”€â”€ embeddings.py    # FAISS indexing
â”‚   â”‚   â””â”€â”€ retrieve.py      # Question retrieval
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ questions.json       # 52 curated questions
â”‚       â””â”€â”€ embeddings.index     # FAISS vector index
â”‚
â”œâ”€â”€ server/              # Express API server
â”‚   â””â”€â”€ index.js         # Question generation + routing
â”‚
â”œâ”€â”€ client/              # React frontend
â”‚   â””â”€â”€ src/components/
â”‚       â”œâ”€â”€ TestMode.jsx       # Mock interview UI
â”‚       â”œâ”€â”€ GuidedMode.jsx     # Study mode
â”‚       â””â”€â”€ SetupScreen.jsx    # Resume input
â”‚
â””â”€â”€ docs/                # Documentation
    â”œâ”€â”€ PRODUCT_NARRATIVE.md    # Why this matters
    â”œâ”€â”€ SCORING_SEMANTICS.md    # Score band definitions
    â””â”€â”€ EVAL_NOTES.md           # Validation template
```

---

## ğŸ“– Documentation

- **[PRODUCT_NARRATIVE.md](PRODUCT_NARRATIVE.md)** - Why RAG-grounded evaluation matters
- **[SCORING_SEMANTICS.md](SCORING_SEMANTICS.md)** - Locked score band definitions
- **[IMPLEMENTATION_STATUS.md](IMPLEMENTATION_STATUS.md)** - Technical implementation details
- **[TESTING_GUIDE.md](TESTING_GUIDE.md)** - How to validate the system
- **[Client README](./client/README.md)** - Frontend documentation
- **[Server README](./server/README.md)** - Backend API documentation
- **[AI Service README](./ai_service/README.md)** - RAG system documentation

---

## ğŸ¯ Design Decisions

### Why Local AI (Phi-3)?
- âœ… **Zero API costs** - Run unlimited evaluations
- âœ… **Fast** - No network latency
- âœ… **Consistent** - Same model, same results
- âœ… **No vendor lock-in** - Not tied to GPT/Claude pricing
- âš ï¸ **Tradeoff**: Requires Ollama setup (cloud fallback available)

### Why RAG?
- âœ… **Grounded in reality** - Compares to known good answers
- âœ… **Explainable scores** - Can show which ideal points were missed
- âœ… **Consistent** - Same answer quality â†’ same score
- âš ï¸ **Tradeoff**: Limited to question bank size (52 curated questions)

### Why Locked Score Bands?
- âœ… **Meaningful** - Users know what 67 means
- âœ… **Consistent** - Not arbitrary numbers
- âœ… **Educational** - Teaches what "good" looks like
- âš ï¸ **Tradeoff**: Less granular than 0-100 scale

### Why 52 Questions, Not 500?
- âœ… **Quality over quantity** - Every question curated with good ideal_points
- âœ… **Maintainable** - Can iterate on quality
- âœ… **Testable** - Small enough to validate manually
- âš ï¸ **Tradeoff**: Limited domain coverage (focused on key roles)

---

## ğŸ¬ Demo Script (2 minutes)

**The Problem** (30s)  
"Traditional AI interview tools give arbitrary scores. You get 67/100 but don't know if that's good, or what to improve."

**The Solution** (60s)  
"MockMate uses RAG - Retrieval-Augmented Generation. When you answer, it retrieves similar questions from a curated bank, compares to their ideal points, and assigns you to a locked score band.

[Show evaluation]

See? 42/100 = âš ï¸ SURFACE LEVEL. It tells you you mentioned useState but missed useEffect, custom hooks, and composition. That's specific feedback grounded in reference standards."

**The Tech** (30s)  
"It runs locally with Phi-3 + FAISS for vector search. No API costs, no vendor lock-in. The question bank has 52 curated questions - quality over quantity.

This is the difference between 'I asked GPT' and 'I built a grounded evaluation system.'"

---

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Additional curated questions with quality ideal_points
- Refinement of existing ideal_points based on validation
- UI/UX polish for score band display
- Documentation improvements

Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ‘¤ Author

**Vansh Tambi**
- GitHub: [@vansh-tambi](https://github.com/vansh-tambi)
- Project: [MockMate](https://github.com/vansh-tambi/MockMate)

---

## ğŸ™ Acknowledgments

- **Ollama** - Local LLM infrastructure
- **Sentence Transformers** - Semantic embedding models
- **React & FastAPI communities** - Excellent developer experience

---

**Built with judgment, not just code.** ğŸš€

---

## ğŸ“‚ Project Structure

```
MockMate/
â”œâ”€â”€ client/                 # Frontend React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ GuidedMode.jsx      # Study mode with Q&A cards
â”‚   â”‚   â”‚   â”œâ”€â”€ TestMode.jsx        # Mock interview simulator
â”‚   â”‚   â”‚   â”œâ”€â”€ SetupScreen.jsx     # Resume/job input
â”‚   â”‚   â”‚   â””â”€â”€ Navbar.jsx          # Navigation bar
â”‚   â”‚   â”œâ”€â”€ App.jsx         # Main application component
â”‚   â”‚   â”œâ”€â”€ main.jsx        # Application entry point
â”‚   â”‚   â””â”€â”€ index.css       # Global styles
â”‚   â”œâ”€â”€ public/             # Static assets
â”‚   â”œâ”€â”€ package.json        # Frontend dependencies
â”‚   â””â”€â”€ README.md           # Client documentation
â”‚
â”œâ”€â”€ server/                 # Backend Express server
â”‚   â”œâ”€â”€ index.js            # Server entry point & API routes
â”‚   â”œâ”€â”€ CLEANED_QUESTIONS.txt  # Question bank
â”‚   â”œâ”€â”€ package.json        # Backend dependencies
â”‚   â””â”€â”€ README.md           # Server documentation
â”‚
â”œâ”€â”€ test_randomization.py   # Testing utilities
â””â”€â”€ README.md               # This file
```

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **React 19.2** - UI framework
- **Vite** - Build tool and dev server
- **TailwindCSS 4.1** - Utility-first CSS framework
- **Framer Motion** - Animation library
- **Web Speech API** - Voice recognition

### Backend
- **Node.js** - Runtime environment
- **Express 5** - Web framework
- **Google Generative AI (Gemini)** - AI question generation and evaluation
- **Multer** - File upload handling
- **pdf-parse** - PDF text extraction
- **CORS** - Cross-origin resource sharing

---

## ğŸ“– Documentation

For detailed documentation, please refer to:
- [Client Documentation](./client/README.md) - Frontend setup and components
- [Server Documentation](./server/README.md) - Backend API and endpoints

---

## ğŸ”§ API Overview

### Core Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/parse-resume` | POST | Parse PDF resume and extract text |
| `/api/generate-qa` | POST | Generate personalized interview questions |
| `/api/evaluate` | POST | Evaluate user's answer and provide feedback |

For detailed API documentation, see [Server README](./server/README.md).

---

## ğŸ¨ Key Features Breakdown

### Guided Mode
- Browse AI-curated questions specific to your role
- View expected answer directions and talking points
- Toggle between questions with smooth animations
- Regenerate entire question set for fresh practice

### Test Mode
- Record video and audio for realistic interview practice
- Real-time speech transcription
- Submit answers for AI evaluation
- Receive detailed feedback with strengths and areas for improvement
- Navigate through questions or shuffle them randomly
- Track completion status

### Setup Screen
- Upload resume as PDF or enter manually
- Specify target job role/description
- Beautiful gradient animations and modern UI
- Data validation and error handling

---

## ğŸŒŸ Technologies Used

- **Gemini AI Models:** Intelligent question generation and answer evaluation using Google's latest language models (Gemini 1.5 Flash, Pro, 2.0 Flash)
- **Framer Motion:** Smooth, professional animations throughout the interface
- **Web Speech API:** Browser-native speech recognition for voice input
- **LocalStorage:** Client-side session persistence
- **Responsive Design:** Mobile-friendly interface with TailwindCSS

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the project
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

---

## ğŸ‘¤ Author

**Vansh Tambi**

- GitHub: [@vansh-tambi](https://github.com/vansh-tambi)
- Repository: [MockMate](https://github.com/vansh-tambi/MockMate)

---

## ğŸ™ Acknowledgments

- Google Gemini AI for powerful language model capabilities
- React and Vite teams for excellent developer experience
- TailwindCSS for utility-first styling
- Framer Motion for animation framework

---

## ğŸ› Known Issues & Roadmap

- [ ] Add support for multiple resume formats (DOCX, TXT)
- [ ] Implement interview history tracking
- [ ] Add export functionality for practice sessions
- [ ] Support multiple languages
- [ ] Enhanced analytics and progress tracking
- [ ] Integration with calendar for scheduled practice
- [ ] Dark/Light theme toggle
- [ ] Mobile app version

---

## ğŸ“§ Support

If you have any questions or run into issues, please open an issue on GitHub.

---

**Made with â¤ï¸ by Vansh Tambi**
