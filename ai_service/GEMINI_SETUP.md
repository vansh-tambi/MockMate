# ğŸš€ Gemini API Backup Setup Guide

## Overview
MockMate AI Service now has **automatic fallback to Google Gemini API** if the local Ollama model becomes unavailable. This ensures your interview evaluation system stays online even during local server issues.

---

## âœ… What Was Implemented

### Code Changes
- âœ… Added Google Generative AI library to `requirements.txt`
- âœ… Integrated Gemini API initialization in `app.py`
- âœ… Implemented automatic fallback logic in `/evaluate` endpoint
- âœ… Updated health check endpoint to report Gemini status
- âœ… Added comprehensive error handling and logging

### Documentation Updates
- âœ… Updated README with Gemini configuration instructions
- âœ… Added performance comparison (Ollama vs Gemini)
- âœ… Added troubleshooting guide for Gemini issues
- âœ… Added testing instructions for backup verification

### Testing Tools
- âœ… Created `test_gemini_backup.py` - Automated test script

---

## ğŸ”§ Quick Setup (3 Steps)

### Step 1: Install Dependencies
```bash
cd ai_service
pip install -r requirements.txt
```

**Note:** The requirements.txt now includes `google-generativeai==0.3.0`

### Step 2: Get Gemini API Key
1. Go to https://aistudio.google.com/app/apikey
2. Click "Create API key in new project"
3. Copy the API key

### Step 3: Set Environment Variable

**Windows (PowerShell):**
```powershell
$env:GEMINI_API_KEY = "paste-your-key-here"
```

**Windows (Command Prompt):**
```cmd
set GEMINI_API_KEY=paste-your-key-here
```

**Mac/Linux:**
```bash
export GEMINI_API_KEY="paste-your-key-here"
```

**Verify it's set:**
```bash
# PowerShell
echo $env:GEMINI_API_KEY

# Bash
echo $GEMINI_API_KEY
```

---

## âœ… Testing the Setup

### Test 1: Verify Configuration
```bash
python test_gemini_backup.py
```

Expected output:
```
âœ… GEMINI_API_KEY is set
âœ… Ollama is running
âœ… AI Service is running
  Ollama: connected
  Gemini Backup: available
```

### Test 2: Health Check
```bash
curl http://localhost:8000/health | jq
```

Expected output shows both backends available:
```json
{
  "status": "healthy",
  "ollama": "connected",
  "gemini_backup": "available",
  "rag_enabled": true,
  "active_sessions": 0
}
```

### Test 3: Test Fallback (Optional)
To test the fallback mechanism, stop Ollama:

```bash
# Then make an evaluation request
curl -X POST http://localhost:8000/evaluate \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is Docker?",
    "user_answer": "Docker is a containerization platform",
    "ideal_points": ["Containers", "Isolation", "Deployment"]
  }'
```

You should see in logs:
```
âŒ Ollama failed: Connection refused
âš ï¸ Falling back to Gemini API...
âœ… Evaluation using Gemini API (backup)
```

---

## ğŸ“Š How It Works

### Priority Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evaluation Request     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Try Ollama (Primary)   â”‚ â† Fast, free, local
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
      âŒ If fails
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Try Gemini API (Backup) â”‚ â† Reliable, cloud-based
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
      âŒ If fails
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Return Error (503)     â”‚ â† No backends available
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Comparison

| Aspect | Ollama | Gemini |
|--------|--------|--------|
| Speed | 2-5s | 5-10s |
| Cost | Free | Free (60 req/min) |
| Location | Your machine | Google servers |
| Reliability | Depends on hardware | 99.9% SLA |
| Privacy | Data stays local | Sent to Google |

---

## âš™ï¸ Configuration Options

### Option A: Ollama Only (Default)
Simply don't set `GEMINI_API_KEY`. Service works when Ollama is running, fails when it's down.

```bash
# Service will show:
"gemini_backup": "not available"
```

### Option B: Ollama + Gemini Backup (Recommended)
Set `GEMINI_API_KEY` for automatic failover.

```bash
$env:GEMINI_API_KEY = "your-api-key"

# Service will show:
"gemini_backup": "available"
```

When Ollama is down, requests automatically use Gemini with no error thrown.

---

## ğŸ› Troubleshooting

### Q: "Gemini API key not provided"
**A:** Set the `GEMINI_API_KEY` environment variable:
```powershell
$env:GEMINI_API_KEY = "your-key"
```

### Q: Health check shows "gemini_backup: not available"
**A:** 
1. Check if package is installed: `pip list | findstr google-generativeai`
2. If not: `pip install google-generativeai==0.3.0`
3. Restart the service

### Q: Gemini evaluation returns error
**A:**
1. Verify API key is valid: Visit https://aistudio.google.com/app/apikey
2. Check rate limit: Free tier has 60 requests/minute
3. Verify internet connection for cloud fallback

### Q: Why is fallback not working?
**A:** Check startup logs. Service prints messages like:
```
âœ… Gemini API configured successfully (backup available)
```
or
```
âš ï¸ Gemini API key not provided (set GEMINI_API_KEY env var)
```

---

## ğŸ“‹ Files Changed

### Modified Files
- `requirements.txt` - Added google-generativeai
- `app.py` - Added Gemini integration and fallback logic
- `README.md` - Comprehensive documentation

### New Files
- `test_gemini_backup.py` - Automated testing script
- `GEMINI_SETUP.md` - This guide

---

## ğŸ¯ What's Next

1. **Set your API key** (3 min)
2. **Run test script** (1 min)
3. **Verify health endpoint** (1 min)
4. **Optionally test fallback** (2 min)

**Total setup time: ~7 minutes**

---

## ğŸ“š Additional Resources

- [Gemini API Documentation](https://ai.google.dev/docs)
- [MockMate AI Service README](README.md)
- [Google AI Studio](https://aistudio.google.com)

---

## âœ¨ Summary

Your MockMate AI Service now has:
- âœ… **Primary backend**: Local Ollama (fast, free)
- âœ… **Backup backend**: Google Gemini (reliable, cloud)
- âœ… **Automatic failover**: No manual intervention needed
- âœ… **Transparent status**: Health endpoint shows which is active
- âœ… **Comprehensive logging**: Detailed messages for debugging

**Result**: Production-grade reliability for interview evaluations! ğŸš€
